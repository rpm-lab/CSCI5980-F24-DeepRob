---
layout: page
title: Syllabus
description: Course policies and information pertaining to Deep Learning for Robot Perception and Manipulation at the University of Minnesota.
nav_order: 2
---

# Course Syllabus
{:.no_toc}

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## About

Robots need to see and understand their world to be able to interact with objects and perform useful tasks autonomously. Perception is the essential first step in the process for endowing robots to perform autonomously.  Autonomous robots need to make sense of their sensory observations to represent the world around them – and enable their reasoning and action to a goal. Visual perception with cameras as sensors has matured due to the recent advancements in neural networks – which is especially true for performing visual recognition tasks such as object classification, detection, pose estimation, grasp pose detection, etc. 

This course aims to cover the necessary background of neural-network-based deep learning for robot perception – building on advancements in computer vision and enabling – for enabling robots to dexterously manipulate physical objects. During the first part of this course, students will learn to implement, train and debug their own neural networks. During the second part of this course, students will explore recent emerging topics in deep learning for robot perception and manipulation.  This exploration will include analysis of research publications in the area, building up to reproducing one of these publications for implementation as a final course project.

This course builds on and is indebted to these existing courses (as a “star” and a "fork" in the open source sense):
- [University of Michigan - EECS 498-007 / 598-005: Deep Learning for Computer Vision](https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/schedule.html){:target="_blank"} instructed by [Justin Johnson](https://web.eecs.umich.edu/~justincj/){:target="_blank"}
- [Stanford - CS231n: Deep Learning for Computer Vision](http://cs231n.stanford.edu/index.html){:target="_blank"} instructed by [Fei-Fei Li](https://profiles.stanford.edu/fei-fei-li){:target="_blank"} and [Andrej Karpathy](https://karpathy.ai/){:target="_blank"}


## Topics and Course Structure

The first half of the course will cover deep learning fundamentals in computer vision catered to robot perception problems.

- Linear classifiers
- Stochastic gradient descent
- Fully-connected networks
- Convolutional networks
- Pose estimation

The second half of the course will switch to seminar style covering following advanced topics in robot perception and manipulation via discussing publications.

- 3D vision in robotics
- Object perception for robot manipulation
- Neural radiance fields for perception
- Robot grasp pose detection

## Prerequisites

- Strongly encouraged prerequisites:
  - Linear Algebra, Calculus, and Probability
  - Programming fluency in data structures in a classical programming language is essential.  
  - Prior experience with the [Python programming language](https://www.python.org/) is strongly recommended.

- Recommended prerequisites: 
  - CSCI 5511 - Artificial Intelligence I
  - CSCI 5521 - Machine Learning Fundamentals
    - Familiarity with concepts from machine learning will be helpful.
  - CSCI 5551 - Introduction to Intelligent Robotic Systems


## Lectures

Lectures will take place in-person on **Tuesdays and Thursdays from 2:30-3:45 PM CT in room TBD**.

<!-- ## Discussion Sections

Discussions will take place in-person with remote accessibility (synchronous and asynchronous). 

In-person discussions will be held on **Fridays from 4:30-5:30 PM EST in room 1060 FMCRB**. -->

## Grading Policy

 - Quizzes:  16x1%=16%  
 - Project 0:     12%
 - Project 1:     12%
 - Project 2:     12%
 - Project 3:     12%
 - Project 4:     12%
 - Final Project: 24%

<!-- ## Project List

- Project 0 (Week 1): Python refresher and warmup
- Project 1 (Weeks 2-3): Intro to pytorch, KNN classifier
- Project 2 (Weeks 4-5): Linear layers, two-layer classifier
- Project 3 (Weeks 6-7): Fully connected neural networks, convolutional neural networks
- Project 4 (Weeks 8-10): Autograd, autoencoder, pose estimation
- Final project (Weeks 11-13): Research paper reproduction, opetions include:
  - [INeRF](https://arxiv.org/abs/2012.05877)
  - [DPF: Differentiable Particle Filter](https://arxiv.org/abs/1805.11122)
  - [GDP: Grasp Pose Detection](https://arxiv.org/abs/1706.09911)
  - [Implicit Fields for manipulation](https://imrss2022.github.io)
- Final project (Weeks 14-15): Research paper extension and report

 -->